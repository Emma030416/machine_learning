## 特征降维
降低特征维度，去除不重要的特征，提高模型的泛化能力<br>
怎样的特征才是不重要的？<br>
低方差特征：波动范围小，信息量少，模型很难学习到信息

常用方法：低方差过滤法，PCA，相关系数法

### 低方差过滤法
删除方差低于设定阈值的特征

#### 📌 关键参数
threshold：方差阈值<br>
作用：删除低于阈值的特征<br>
默认为0，因为方差大于等于零，所以就是保留了所有非零方差特征，删除具有相同值的特征

#### 📌 实战案例
``` python
# 1.导包
from sklearn.feature_selection import VarianceThreshold # 用于低方差过滤
import pandas as pd # 用于读取csv文本的数据

# 2.读取数据
data = pd.read_csv('.\data\垃圾邮件分类数据.csv', encoding = 'utf-8')
print(data.shape)

# 3.特征工程（用低方差过滤法进行特征降维）
transformer = VarianceThreshold(threshold=0.1) # 低方差过滤器
X = transformer.fit_transform(data) # 放入数据，特征降维
```

### PCA(主成分分析)
压缩特征维度，降低复杂度<br>
将高维数据投影到低维平面（如3D→2D），通过统计指标（主要是方差）判断特征重要性

#### 📌 关键参数
n_components：<br>
小数形式（如0.95）：保留95%的信息量<br>
整数形式（如8）：保留8个特征<br>

#### 📌 实战案例
基本和低方差过滤法一样

``` python
# 1.导包
from sklearn.decomposition import PCA # 用于PCA
import pandas as pd # 用于读取csv文本的数据

# 2.读取数据
data = pd.read_csv('.\data\垃圾邮件分类数据.csv', encoding = 'utf-8')
print(data.shape)

# 3.特征工程（用PCA进行特征降维）
transformer = PCA(n_components=0.95)
X = transformer.fit_transform(data) # 放入数据，特征降维
```

## 相关系数法



